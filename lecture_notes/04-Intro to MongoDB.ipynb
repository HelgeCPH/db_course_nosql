{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why do we need yet another database?\n",
    "\n",
    "\n",
    "## MongoDB’s key features\n",
    "\n",
    "A database is defined in large part by its data model. In this section, you’ll look at the document data model, and then you’ll see the features of MongoDB that allow you to operate effectively on that model. This section also explores operations, focusing on MongoDB’s flavor of replication and its strategy for scaling horizontally.\n",
    "\n",
    "\n",
    "### Document data model\n",
    "\n",
    "\n",
    "\n",
    "Document databases offer the most immediately familiar paradigm for developers used to working with hierarchically structured documents. Document databases store and retrieve documents, just like an electronic filing cabinet. Documents tend to comprise maps and lists, allowing for natural hierarchies—much as we’re used to with formats like JSON and XML.\n",
    "\n",
    "\n",
    "A document is essentially a **set of property names and their values**. The values can be simple data types, such as strings, numbers, and dates. But these values can also be arrays and even other JSON documents. \n",
    "\n",
    "Note, a JSON document needs double quotes everywhere except for numeric values. The following listing shows the JavaScript version of a JSON document where double quotes aren’t necessary.\n",
    "\n",
    "```javascript\n",
    "{\n",
    "  _id: ObjectID('4bd9e8e17cefd644108961bb'),     // _id field, primary key\n",
    "  title: 'Adventures in Databases',\n",
    "  url: 'http://example.com/databases.txt',\n",
    "  author: 'msmith',\n",
    "  vote_count: 20,\n",
    "  tags: ['databases', 'mongodb', 'indexing'],    // Tags stored as array of strings\n",
    "  image: {                                       // Attribute pointing to another document\n",
    "    url: 'http://example.com/db.jpg',\n",
    "    caption: 'A database.',\n",
    "    type: 'jpg',\n",
    "    size: 75381,\n",
    "    data: 'Binary'\n",
    "  },\n",
    "  comments: [                                    // Comments stored as array of comment objects\n",
    "    {\n",
    "      user: 'bjones',\n",
    "      text: 'Interesting article.'\n",
    "    },\n",
    "    {\n",
    "      user: 'sverch',\n",
    "      text: 'Color me skeptical!'\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "Internally, MongoDB stores documents in a format called Binary JSON, or **BSON**. BSON has a similar structure but is intended for storing many documents.\n",
    "\n",
    "Where relational databases have tables, MongoDB has **collections**. In other words, MySQL (a popular relational database) keeps its data in tables of rows, while MongoDB keeps its data in collections of documents, which you can think of as a group of documents.\n",
    "\n",
    "A document-oriented data model naturally represents **data in an aggregate form**, allowing you to work with an object holistically: all the data representing a post, from comments to tags, can be fitted into a single database object.\n",
    "\n",
    "You’ve probably noticed that in addition to providing a richness of structure, **documents needn’t conform to a prespecified schema**. With a relational database, you store rows in a table. Each table has a strictly defined schema specifying which columns and types are permitted. If any row in a table needs an extra field, you have to alter the table explicitly.\n",
    "\n",
    "\n",
    "\n",
    "#### Schema-less Model Advantages\n",
    "\n",
    "This lack of imposed schema confers some advantages. \n",
    "\n",
    "  * Application code, and not the database, enforces the data’s structure. This can speed up initial application development when the schema is changing frequently.\n",
    "  * A schema-less model allows you to represent data with truly variable properties. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Ad hoc queries\n",
    "\n",
    "Not all databases support dynamic queries. For instance, key-value stores are queryable on one axis only: the value’s key. Like many other systems, key-value stores sacrifice rich query power in exchange for a simple scalability model. \n",
    "\n",
    "One of MongoDB’s design goals is to preserve most of the query power that’s been so fundamental to the relational database world.\n",
    "\n",
    "To see how MongoDB’s query language works, let’s take a simple example involving posts and comments. Suppose you want to find all posts tagged with the term poli- tics having more than 10 votes. A SQL query would look like this:\n",
    "\n",
    "```sql\n",
    "SELECT * FROM posts\n",
    "  INNER JOIN posts_tags ON posts.id = posts_tags.post_id\n",
    "  INNER JOIN tags ON posts_tags.tag_id == tags.id\n",
    "  WHERE tags.text = 'politics' AND posts.vote_count > 10;  \n",
    "```\n",
    "\n",
    "\n",
    "The equivalent query in MongoDB is specified using a document as a matcher. The special $gt key indicates the greater-than condition:\n",
    "\n",
    "```js\n",
    "db.posts.find({'tags': 'politics', 'vote_count': {'$gt': 10}});\n",
    "```\n",
    "\n",
    "**OBS**: the two queries assume a different data model. The SQL query relies on a strictly normalized model, where posts and tags are stored in distinct tables, whereas the MongoDB query assumes that tags are stored within each post document. But both queries demonstrate an ability to query on arbitrary combinations of attributes, which is the essence of ad hoc query ability.\n",
    "\n",
    "\n",
    "### Indexes\n",
    "\n",
    "A critical element of ad hoc queries is that they search for values that you don’t know when you create the database. As you add more and more documents to your database, searching for a value becomes increasingly expensive; it’s a needle in an ever-expanding haystack. \n",
    "\n",
    "Indexes in MongoDB are implemented as a B-tree data structure. B-tree indexes, also used in many relational databases, are optimized for a variety of queries, including range scans and queries with sort clauses.\n",
    "\n",
    "Most databases give each document or row a primary key, a unique identifier for that datum. The primary key is generally indexed automatically so that each datum can be efficiently accessed using its unique key, and MongoDB is no different. But not every database allows you to also index the data inside that row or document. These are called secondary indexes. Many NoSQL databases, such as HBase, are considered key-value stores because they don’t allow any secondary indexes. This is a significant feature in MongoDB; by permitting multiple secondary indexes MongoDB allows users to optimize for a wide variety of queries.\n",
    "\n",
    "With MongoDB, you can create up to 64 indexes per collection. The kinds of indexes supported include all the ones you’d find in an RDMBS; ascending, descending, unique, compound-key, hashed, text, and even geospatial indexes are supported.\n",
    "\n",
    "\n",
    "### Replication\n",
    "\n",
    "MongoDB provides database replication via a topology known as a replica set. Replica sets distribute data across two or more machines for redundancy and automate failover in the event of server and network outages. Additionally, replication is used to scale database reads. If you have a read-intensive application, as is commonly the case on the web, it’s possible to spread database reads across machines in the replica set cluster.\n",
    "\n",
    "Replica sets consist of many MongoDB servers, usu- ally with each server on a separate physical machine; we’ll call these nodes. At any given time, one node serves as the replica set primary node and one or more nodes serve as secondaries. Like the master-slave repli- cation that you may be familiar with from other data- bases, a replica set’s primary node can accept both reads and writes, but the secondary nodes are read- only. What makes replica sets unique is their support for automated failover: if the primary node fails, the cluster will pick a secondary node and automatically promote it to primary. When the former primary comes back online, it’ll do so as a secondary.\n",
    "\n",
    "\n",
    "### Speed and durability\n",
    "\n",
    "In the realm of database systems there exists an inverse relationship between *write speed* and *durability*. Write speed can be understood as the volume of inserts, updates, and deletes that a database can process in a given time frame. Durability refers to level of assurance that these write operations have been made permanent.\n",
    "\n",
    "For instance, suppose you write 100 records of 50KB each to a database and then immediately cut the\n",
    "power on the server. Will those records be recoverable when you bring the machine back online? The answer\n",
    "depends on your database system, its configuration, and the hardware hosting it.\n",
    "\n",
    "In MongoDB’s case, users control the speed and durability trade-off by choosing write semantics and deciding whether to enable journaling. \n",
    "\n",
    "You can configure MongoDB to **fire-and-forget**, sending off a write to the server without waiting for an acknowledgment. You can also configure MongoDB to guarantee that a write has gone to **multiple replicas before** considering it committed. For high-volume, low-value data (like clickstreams and logs), fire-and-forget-style writes can be ideal. For important data, a safe mode setting is necessary. \n",
    "\n",
    "Since MongoDB v2.0, **journaling** is enabled by default. With journaling, every write is flushed to the journal file every 100 ms. If the server is ever shut down uncleanly (say, in a power outage), the journal will be used to ensure that MongoDB’s data files are restored to a consistent state when you restart the server. This is the safest way to run MongoDB.\n",
    "\n",
    "### Scaling\n",
    "\n",
    "The easiest way to scale most databases is to upgrade the hardware. If your application is running on a single node, it’s usually possible to add some combination of faster disks, more memory, and a beefier CPU to ease any database bottlenecks. The technique of augmenting a single node’s hardware for scale is known as **vertical scaling**, or scaling up. Vertical scaling has the advantages of being simple, reliable, and cost-effective up to a certain point, but eventually you reach a point where it’s no longer feasible to move to a better machine.\n",
    "\n",
    "It then makes sense to consider **scaling horizontally**, or scaling out. Instead of beefing up a single node, scaling horizontally means distributing the database across multiple machines. A horizontally scaled architecture can run on many smaller, less expensive machines, often reducing your hosting costs. What’s more, the distribution of data across machines mitigates the consequences of failure. \n",
    "\n",
    "MongoDB was designed to make horizontal scaling manageable. It does so via a range-based partitioning mechanism, known as sharding, which automatically manages the distribution of data across nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison to other types of databases.\n",
    "\n",
    "\n",
    "The following is an excerpt from: Ian Robinson, Jim Webber, Emil Eifrem. *\"Graph Databases.\"*\n",
    "\n",
    "\n",
    "Volume has become the principal driver behind the adoption of NOSQL stores by organizations. Volume may be defined simply as the size of the stored data.\n",
    "\n",
    "As is well known, large datasets become unwieldy when stored in relational databases. In particular, query execution times increase as the size of tables and the number of joins grow (so-called join pain). \n",
    "\n",
    "But volume isn’t the only problem modern web-facing systems have to deal with. Besides being big, today’s data often changes very rapidly. Velocity is the rate at which data changes over time.\n",
    "\n",
    "\n",
    "There is another aspect to velocity, which is the rate at which the structure of the data changes. In other words, in addition to the value of specific properties changing, the overall structure of the elements hosting those properties can change as well. This commonly occurs for two reasons. The first is fast-moving business dynamics.\n",
    "\n",
    "\n",
    "\n",
    "## ACID versus BASE\n",
    "When we first encounter NOSQL it’s often in the context of what many of us are already familiar with: relational databases. Although we know the data and query model will be different (after all, there’s no SQL), the **consistency models used by NOSQL stores can also be quite different from those employed by relational databases**. Many NOSQL databases use different consistency models to support the differences in volume, velocity, and variety of data discussed earlier.\n",
    "\n",
    "\n",
    "The **ACID** guarantees provide us with a safe environment in which to operate on data:\n",
    "\n",
    "  * **Atomic**\n",
    "    All operations in a transaction succeed or every operation is rolled back.\n",
    "  * **Consistent**\n",
    "    On transaction completion, the database is structurally sound.\n",
    "  * **Isolated**\n",
    "    Transactions do not contend with one another. Contentious access to state is moderated by the database so that transactions appear to run sequentially.\n",
    "  * **Durable**\n",
    "    The results of applying a transaction are permanent, even in the presence of failures.\n",
    "\n",
    "These properties mean that once a transaction completes, its data is consistent (so-called write consistency) and stable on disk (or disks, or indeed in multiple distinct memory locations). \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "In the NOSQL world, ACID transactions have gone out of fashion as stores loosen the requirements for immediate consistency, data freshness, and accuracy in order to gain other benefits, like scale and resilience. Instead of using ACID, the term **BASE** has arisen as a popular way of describing the properties of a more optimistic storage strategy:\n",
    "\n",
    "  * **Basic availability** The store appears to work most of the time.\n",
    "  * **Soft-state** Stores don’t have to be write-consistent, nor do different replicas have to be mutually consistent all the time.\n",
    "  * **Eventual consistency** Stores exhibit consistency at some later point (e.g., lazily at read time).\n",
    "  \n",
    "The BASE properties are considerably looser than the ACID guarantees, and there is no direct mapping between them. A BASE store values availability (because that is a core building block for scale), but does not offer guaranteed consistency of replicas at write time. BASE stores provide a less strict assurance: that data will be consistent in the future, perhaps at read time (e.g., Riak), or will always be consistent, but only for certain processed past snapshots (e.g., Datomic).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Popular GUI Client - Robomongo\n",
    "\n",
    "Robomongo (https://robomongo.org) is a cross-platform MongoDB manager.\n",
    "\n",
    "![](https://robomongo.org/static/screens-transparent-6e2a44fd.png)\n",
    "\n",
    "You can create a connection to the MongoDB on the VM by creating a new connection with the address `localhost:27017`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MongoDB through the JavaScript shell\n",
    "\n",
    "\n",
    "## Starting the shell\n",
    "\n",
    "See the instructions in the Vagrant provision script, for an example of how to install MongoDB on a Linux system.\n",
    "\n",
    "On the VM you can start the MongoDB shell by running the mongo executable:\n",
    "\n",
    "```bash\n",
    "mongo\n",
    "```\n",
    "\n",
    "### Databases, Collections, and Documents\n",
    "\n",
    "Imagine we are crating a small social network application and our database has to store different types of documents, like *users*, *comments*, etc.. Those are stored in separate places, i.e., **collections**, which are similar to tables in an RDBMS. MongoDB divides collections into separate databases. Unlike the usual overhead that databases produce in the SQL world, databases in MongoDB are just **namespaces** to distinguish between collections. \n",
    "\n",
    "\n",
    "the subsequent tutorial exercises under the same namespace, let’s start by switching to the tutorial database:\n",
    "\n",
    "\n",
    "```mongo\n",
    "> use class\n",
    "switched to db class\n",
    "```    \n",
    "    \n",
    "Why does MongoDB have both databases and collections? The answer lies in how MongoDB writes its data out to disk. All collections in a database are grouped in the same files, so it makes sense, from a memory perspective, to keep related collections in the same database. You might also want to have different applications access the same collections and, it’s also useful to keep your data organized so you’re prepared for future requirements.\n",
    "\n",
    "\n",
    "### Inserts and Queries\n",
    "\n",
    "```mongo\n",
    "> db.users.insert({username: \"Møller\"})\n",
    "WriteResult({ \"nInserted\" : 1 })\n",
    "```\n",
    "\n",
    "```mongo\n",
    "> db.users.find()\n",
    "{ \"_id\" : ObjectId(\"58de3ef059f6af55dbf09bbc\"), \"username\" : \"Møller\" }\n",
    "```\n",
    "\n",
    "#### `_id` Fields in MongoDB\n",
    "\n",
    "Note that an `_id` field has been added to the document. You can think of the `_id` value as the document’s primary key. Every MongoDB document requires an `_id`, and if one isn’t present when the document is created, a special MongoDB ObjectID will be generated and added to the document at that time.\n",
    "\n",
    "Let’s continue for now by adding a second user to the collection:\n",
    "\n",
    "```mongo\n",
    "> db.users.insert({username: \"Hansen\"})\n",
    "WriteResult({ \"nInserted\" : 1 })\n",
    "```\n",
    "\n",
    "There should now be two documents in the collection. Go ahead and verify this by running the count command:Hansen\n",
    "\n",
    "```mongo\n",
    "> db.users.count()\n",
    "2\n",
    "> db.users.find()\n",
    "{ \"_id\" : ObjectId(\"58de3ef059f6af55dbf09bbc\"), \"username\" : \"Møller\" }\n",
    "{ \"_id\" : ObjectId(\"58de3fbf59f6af55dbf09bbd\"), \"username\" : \"Hansen\" }\n",
    "```\n",
    "\n",
    "\n",
    "You can also pass a simple query selector to the find method. A query selector is a document that is used to match against all documents in the collection. To query for all documents where the username is `Hansen`, you pass a simple document that acts as your query selector like this:\n",
    "\n",
    "```mongo\n",
    "> db.users.find({username: \"Hansen\"})\n",
    "{ \"_id\" : ObjectId(\"58de3fbf59f6af55dbf09bbd\"), \"username\" : \"Hansen\" }\n",
    "```\n",
    "\n",
    "\n",
    "You can also specify multiple fields in the query predicate, which creates an implicit **AND** among the fields. For example, you query with the following selector:\n",
    "\n",
    "```mongo\n",
    "> db.users.find({ _id: ObjectId(\"58de3fbf59f6af55dbf09bbd\"), username: \"Hansen\" })\n",
    "{ \"_id\" : ObjectId(\"58de3fbf59f6af55dbf09bbd\"), \"username\" : \"Hansen\" }\n",
    "```\n",
    "\n",
    "You can also use MongoDB’s `$and` operator explicitly. The previous query is identical to\n",
    "\n",
    "```mongo\n",
    "> db.users.find({ $and: [ { _id: ObjectId(\"58de3fbf59f6af55dbf09bbd\") }, { username: \"Hansen\" } ] })\n",
    "{ \"_id\" : ObjectId(\"58de3fbf59f6af55dbf09bbd\"), \"username\" : \"Hansen\" }\n",
    "```\n",
    "\n",
    "Selecting documents with an **OR** is similar: just use the `$or` operator.\n",
    "\n",
    "```mongo\n",
    "> db.users.find({ $or: [ { username: \"Møller\" }, { username: \"Hansen\" } ]})\n",
    "{ \"_id\" : ObjectId(\"58de3ef059f6af55dbf09bbc\"), \"username\" : \"Møller\" }\n",
    "{ \"_id\" : ObjectId(\"58de3fbf59f6af55dbf09bbd\"), \"username\" : \"Hansen\" }\n",
    "```\n",
    "\n",
    "This example is different than previous ones, because it does not just insert or search for a specific document. Rather, the query itself is a document. The idea of representing commands as documents is used often in MongoDB and may come as a surprise if you’re used to relational databases.\n",
    "\n",
    "### Updating Documents\n",
    "\n",
    "There are two general types of updates, with different properties and use cases:\n",
    "  * Apply modification operations to a document or documents\n",
    "  * Replace an old document with a new one\n",
    "  \n",
    "#### Operator Update\n",
    "\n",
    "The first type of update involves passing a document with some kind of operator description as the second argument to the update function. Here we see an example of how to use the `$set` operator, which sets a single field to the specified value.\n",
    "\n",
    "```mongo\n",
    "> db.users.update({username: \"Møller\"}, {$set: {country: \"Denmark\"}})\n",
    "WriteResult({ \"nMatched\" : 1, \"nUpserted\" : 0, \"nModified\" : 1 })\n",
    "> db.users.find({username: \"Møller\"})\n",
    "{ \"_id\" : ObjectId(\"58de3ef059f6af55dbf09bbc\"), \"username\" : \"Møller\", \"country\" : \"Denmark\" }\n",
    "```\n",
    "\n",
    "#### Replacement Update\n",
    "\n",
    "Another way to update a document is to replace it rather than just set a field. This is sometimes mistakenly used when an operator update with a `$set` was intended.\n",
    "\n",
    "```mongo\n",
    "> db.users.update({username: \"Møller\"}, {country: \"Canada\"})\n",
    "WriteResult({ \"nMatched\" : 1, \"nUpserted\" : 0, \"nModified\" : 1 })\n",
    "> db.users.find({username: \"Møller\"})\n",
    "> db.users.find({country: \"Canada\"})\n",
    "{ \"_id\" : ObjectId(\"58de3ef059f6af55dbf09bbc\"), \"country\" : \"Canada\" }\n",
    "```\n",
    "\n",
    "In this case, the document is **replaced** with one that only contains the country field, and the username field is removed because the first document is used only for matching and the second document is used for replacing the document that was previously matched. The `_id` is the same, yet data has been replaced in the update. Be sure to use the `$set` operator if you intend to add or set fields rather than to replace the entire document. \n",
    "\n",
    "\n",
    "To  Add the username back to the record:\n",
    "\n",
    "```mongo\n",
    "> db.users.update({country: \"Canada\"}, {$set: {username: \"Møller\"}})\n",
    "WriteResult({ \"nMatched\" : 1, \"nUpserted\" : 0, \"nModified\" : 1 })\n",
    "> db.users.find({country: \"Canada\"})\n",
    "{ \"_id\" : ObjectId(\"58de3ef059f6af55dbf09bbc\"), \"country\" : \"Canada\", \"username\" : \"Møller\" }\n",
    "```\n",
    "\n",
    "A value can be removed as easily using the `$unset` operator:\n",
    "\n",
    "```mongo\n",
    "> db.users.update({username: \"Møller\"}, {$unset: {country: 1}} )\n",
    "WriteResult({ \"nMatched\" : 1, \"nUpserted\" : 0, \"nModified\" : 1 })\n",
    "> db.users.find({username: \"Møller\"})\n",
    "{ \"_id\" : ObjectId(\"58de3ef059f6af55dbf09bbc\"), \"username\" : \"Møller\" }\n",
    "```\n",
    "\n",
    "#### Updating Complex Data\n",
    "\n",
    "You are representing your data with documents, which can contain complex data structures. Let’s suppose that, in addi tion to storing profile information, your users can store lists of their favorite things. A document representation might look something like this:\n",
    "\n",
    "```javascript\n",
    "{\n",
    "  username: \"Møller\",\n",
    "  favorites: {\n",
    "    restaurant: [\"La Petanque\", \"Hija de Sanchez\"],\n",
    "    cafe: [\"Paludan Bog & Café\", \"Café Retro\", \"Conditori La Glace\"]\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "\n",
    "```mongo\n",
    "> db.users.update( {username: \"Møller\"}, { $set: {favorites: { restaurant: [\"La Petanque\", \"Hija de Sanchez\"], cafe: [\"Paludan Bog & Café\", \"Café Retro\", \"Conditori La Glace\"] }} })\n",
    "WriteResult({ \"nMatched\" : 1, \"nUpserted\" : 0, \"nModified\" : 1 })\n",
    "> db.users.update( {username: \"Hansen\"}, { $set: {favorites: { cafe: [\"Vaffelbageren\", \"Café BoPa\", \"Conditori La Glace\"] }} })\n",
    "WriteResult({ \"nMatched\" : 1, \"nUpserted\" : 0, \"nModified\" : 1 })\n",
    "> db.users.find().pretty()\n",
    "{\n",
    "\t\"_id\" : ObjectId(\"58de3ef059f6af55dbf09bbc\"),\n",
    "\t\"username\" : \"Møller\",\n",
    "\t\"favorites\" : {\n",
    "\t\t\"restaurant\" : [\n",
    "\t\t\t\"La Petanque\",\n",
    "\t\t\t\"Hija de Sanchez\"\n",
    "\t\t],\n",
    "\t\t\"cafe\" : [\n",
    "\t\t\t\"Paludan Bog & Café\",\n",
    "\t\t\t\"Café Retro\",\n",
    "\t\t\t\"Conditori La Glace\"\n",
    "\t\t]\n",
    "\t}\n",
    "}\n",
    "{\n",
    "\t\"_id\" : ObjectId(\"58de3fbf59f6af55dbf09bbd\"),\n",
    "\t\"username\" : \"Hansen\",\n",
    "\t\"favorites\" : {\n",
    "\t\t\"cafe\" : [\n",
    "\t\t\t\"Vaffelbageren\",\n",
    "\t\t\t\"Café BoPa\",\n",
    "            \"Conditori La Glace\"\n",
    "\t\t]\n",
    "\t}\n",
    "}\n",
    "```\n",
    "\n",
    "```mongo\n",
    "> db.users.find({\"favorites.cafe\": \"Conditori La Glace\"})\n",
    "{ \"_id\" : ObjectId(\"58de3ef059f6af55dbf09bbc\"), \"username\" : \"Møller\", \"favorites\" : { \"restaurant\" : [ \"La Petanque\", \"Hija de Sanchez\" ], \"cafe\" : [ \"Paludan Bog & Café\", \"Café Retro\", \"Conditori La Glace\" ] } }\n",
    "{ \"_id\" : ObjectId(\"58de3fbf59f6af55dbf09bbd\"), \"username\" : \"Hansen\", \"favorites\" : { \"cafe\" : [ \"Vaffelbageren\", \"Café BoPa\", \"Conditori La Glace\" ] } }\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "#### More Advanced Updates\n",
    "\n",
    "To see a more involved example, suppose you know that any user who likes `\"Café Retro\"` also likes `\"Lagkagehuset\"` and that you want to update your database to reflect this fact. How would you represent this as a MongoDB update?\n",
    "You could conceivably use the `$set` operator again, but doing so would require you to rewrite and send the entire array of movies. Because all you want to do is to add an ele- ment to the list, you’re better off using either `$push` or `$addToSet`. Both operators add an item to an array, but the second does so uniquely, preventing a duplicate addition. This is the update you’re looking for:\n",
    "\n",
    "```mongo\n",
    "> db.users.update( {\"favorites.cafe\": \"Café Retro\"}, {$addToSet: {\"favorites.cafe\": \"Lagkagehuset\"} }, false, true)\n",
    "WriteResult({ \"nMatched\" : 1, \"nUpserted\" : 0, \"nModified\" : 1 })\n",
    "\n",
    "```\n",
    "\n",
    "The third argument, `false`, controls whether an upsert is allowed. This tells the update operation whether it should insert a document if it doesn’t already exist, which has different behavior depending on whether the update is an operator update or a replacement update.\n",
    "The fourth argument, `true`, indicates that this is a multi-update. By default, a MongoDB update operation will apply only to the first document matched by the query selector. If you want the operation to apply to all documents matched, you must be explicit about that.\n",
    "\n",
    "\n",
    "### Deleting data\n",
    "\n",
    "Delete all contents of a collection:\n",
    "\n",
    "```mongo\n",
    "> db.foo.remove()\n",
    "```\n",
    "\n",
    "Note that the remove() operation doesn’t actually delete the collection; it merely removes documents from a collection. You can think of it as being analogous to SQL’s `DELETE` command.\n",
    "\n",
    "You often need to remove only a certain subset of a collection’s documents, and for that, you can pass a query selector to the `remove()` method. If you want to remove all users whose favorite café is `\"Café Retro\"`, you would do:\n",
    "\n",
    "\n",
    "```mongo\n",
    "> db.users.remove({\"favorites.cafe\": \"Café Retro\"})\n",
    "WriteResult({ \"nRemoved\" : 1 })\n",
    "```\n",
    "\n",
    "\n",
    "To delete a collection along with all of its indexes, use the `drop()` method:\n",
    "\n",
    "```mongo\n",
    "> db.users.drop()\n",
    "```\n",
    "\n",
    "### Getting `help`\n",
    "\n",
    "```mongo\n",
    "> help\n",
    "```\n",
    "\n",
    "\n",
    "```mongo\n",
    "> db.users.help()\n",
    "```\n",
    "\n",
    "\n",
    "### Creating and Querying with Indexes\n",
    "\n",
    "#### Creating a large collection\n",
    "\n",
    "An indexing example makes sense only if you have a collection with many documents. So you’ll add 20,000 simple documents to a numbers collection. Because the MongoDB shell is also a JavaScript interpreter, the code to accomplish this is simple:\n",
    "\n",
    "```mongo\n",
    "> for(i = 0; i < 20000; i++) { db.numbers.save({num: i}); }\n",
    "WriteResult({ \"nInserted\" : 1 })\n",
    "```\n",
    "\n",
    "\n",
    "That’s a lot of documents, so don’t be surprised if the insert takes a few seconds to complete. Once it returns, you can run a couple of queries to verify that all the documents are present:\n",
    "       \n",
    "```mongo       \n",
    "> db.numbers.count()\n",
    "20000\n",
    "> db.numbers.find()\n",
    "{ \"_id\" : ObjectId(\"58de4ec559f6af55dbf09bbe\"), \"num\" : 0 }\n",
    "{ \"_id\" : ObjectId(\"58de4ec559f6af55dbf09bbf\"), \"num\" : 1 }\n",
    "{ \"_id\" : ObjectId(\"58de4ec559f6af55dbf09bc0\"), \"num\" : 2 }\n",
    "{ \"_id\" : ObjectId(\"58de4ec559f6af55dbf09bc1\"), \"num\" : 3 }\n",
    "{ \"_id\" : ObjectId(\"58de4ec559f6af55dbf09bc2\"), \"num\" : 4 }\n",
    "{ \"_id\" : ObjectId(\"58de4ec559f6af55dbf09bc3\"), \"num\" : 5 }\n",
    "{ \"_id\" : ObjectId(\"58de4ec559f6af55dbf09bc4\"), \"num\" : 6 }\n",
    "{ \"_id\" : ObjectId(\"58de4ec559f6af55dbf09bc5\"), \"num\" : 7 }\n",
    "{ \"_id\" : ObjectId(\"58de4ec559f6af55dbf09bc6\"), \"num\" : 8 }\n",
    "{ \"_id\" : ObjectId(\"58de4ec559f6af55dbf09bc7\"), \"num\" : 9 }\n",
    "{ \"_id\" : ObjectId(\"58de4ec559f6af55dbf09bc8\"), \"num\" : 10 }\n",
    "{ \"_id\" : ObjectId(\"58de4ec559f6af55dbf09bc9\"), \"num\" : 11 }\n",
    "{ \"_id\" : ObjectId(\"58de4ec559f6af55dbf09bca\"), \"num\" : 12 }\n",
    "{ \"_id\" : ObjectId(\"58de4ec559f6af55dbf09bcb\"), \"num\" : 13 }\n",
    "{ \"_id\" : ObjectId(\"58de4ec559f6af55dbf09bcc\"), \"num\" : 14 }\n",
    "{ \"_id\" : ObjectId(\"58de4ec559f6af55dbf09bcd\"), \"num\" : 15 }\n",
    "{ \"_id\" : ObjectId(\"58de4ec559f6af55dbf09bce\"), \"num\" : 16 }\n",
    "{ \"_id\" : ObjectId(\"58de4ec559f6af55dbf09bcf\"), \"num\" : 17 }\n",
    "{ \"_id\" : ObjectId(\"58de4ec559f6af55dbf09bd0\"), \"num\" : 18 }\n",
    "{ \"_id\" : ObjectId(\"58de4ec559f6af55dbf09bd1\"), \"num\" : 19 }\n",
    "Type \"it\" for more\n",
    "> db.numbers.find({num: 500})\n",
    "{ \"_id\" : ObjectId(\"58de4ec559f6af55dbf09db2\"), \"num\" : 500 }\n",
    "```\n",
    "\n",
    "#### Range Queries\n",
    "\n",
    "More interestingly, you can also issue range queries using the special `$gt` and `$lt` operators. They stand for greater than and less than, respectively. Here’s how you query for all documents with a num value greater than 199,995:\n",
    "\n",
    "```mongo\n",
    "> db.numbers.find( {num: {\"$gt\": 19995 }} )\n",
    "{ \"_id\" : ObjectId(\"58de4ecb59f6af55dbf0e9da\"), \"num\" : 19996 }\n",
    "{ \"_id\" : ObjectId(\"58de4ecb59f6af55dbf0e9db\"), \"num\" : 19997 }\n",
    "{ \"_id\" : ObjectId(\"58de4ecb59f6af55dbf0e9dc\"), \"num\" : 19998 }\n",
    "{ \"_id\" : ObjectId(\"58de4ecb59f6af55dbf0e9dd\"), \"num\" : 19999 }\n",
    "```\n",
    "\n",
    "You can also combine the two operators to specify upper and lower boundaries:\n",
    " \n",
    "```mongo\n",
    "> db.numbers.find( {num: {\"$gt\": 20, \"$lt\": 25 }} )\n",
    "{ \"_id\" : ObjectId(\"58de4ec559f6af55dbf09bd3\"), \"num\" : 21 }\n",
    "{ \"_id\" : ObjectId(\"58de4ec559f6af55dbf09bd4\"), \"num\" : 22 }\n",
    "{ \"_id\" : ObjectId(\"58de4ec559f6af55dbf09bd5\"), \"num\" : 23 }\n",
    "{ \"_id\" : ObjectId(\"58de4ec559f6af55dbf09bd6\"), \"num\" : 24 }\n",
    "```     \n",
    "\n",
    "`$gt` and `$lt` are only two of a host of operators that comprise the MongoDB query language. Others include `$gte` for greater than or equal to, `$lte` for (you guessed it) less than or equal to, and `$ne` for not equal to. You’ll see other operators and many more example queries in later chapters.\n",
    "\n",
    "\n",
    "#### Indexing and `explain()`\n",
    "\n",
    "If you’ve spent time working with relational databases, you’re probably familiar with SQL’s `EXPLAIN`, an invaluable tool for debugging or optimizing a query. When any database receives a query, it must plan out how to execute it; this is called a query plan. `EXPLAIN` describes query paths and allows developers to diagnose slow operations by determining which indexes a query has used. Often a query can be executed in multiple ways, and sometimes this results in behavior you might not expect. `EXPLAIN` explains. MongoDB has its own version of `EXPLAIN` that provides the same service. To get an idea of how it works, let’s apply it to one of the queries you just issued. Try running the following on your system:\n",
    "\n",
    "```mongo\n",
    "> db.numbers.find({num: {\"$gt\": 19995}}).explain(\"executionStats\")\n",
    "{\n",
    "\t\"cursor\" : \"BasicCursor\",\n",
    "\t\"isMultiKey\" : false,\n",
    "\t\"n\" : 4,\n",
    "\t\"nscannedObjects\" : 20000,\n",
    "\t\"nscanned\" : 20000,\n",
    "\t\"nscannedObjectsAllPlans\" : 20000,\n",
    "\t\"nscannedAllPlans\" : 20000,\n",
    "\t\"scanAndOrder\" : false,\n",
    "\t\"indexOnly\" : false,\n",
    "\t\"nYields\" : 156,\n",
    "\t\"nChunkSkips\" : 0,\n",
    "\t\"millis\" : 5,\n",
    "\t\"allPlans\" : [\n",
    "\t\t{\n",
    "\t\t\t\"cursor\" : \"BasicCursor\",\n",
    "\t\t\t\"isMultiKey\" : false,\n",
    "\t\t\t\"n\" : 4,\n",
    "\t\t\t\"nscannedObjects\" : 20000,\n",
    "\t\t\t\"nscanned\" : 20000,\n",
    "\t\t\t\"scanAndOrder\" : false,\n",
    "\t\t\t\"indexOnly\" : false,\n",
    "\t\t\t\"nChunkSkips\" : 0\n",
    "\t\t}\n",
    "\t],\n",
    "\t\"server\" : \"ubuntu-xenial:27017\",\n",
    "\t\"filterSet\" : false,\n",
    "\t\"stats\" : {\n",
    "\t\t\"type\" : \"COLLSCAN\",\n",
    "\t\t\"works\" : 20002,\n",
    "\t\t\"yields\" : 156,\n",
    "\t\t\"unyields\" : 156,\n",
    "\t\t\"invalidates\" : 0,\n",
    "\t\t\"advanced\" : 4,\n",
    "\t\t\"needTime\" : 19997,\n",
    "\t\t\"needFetch\" : 0,\n",
    "\t\t\"isEOF\" : 1,\n",
    "\t\t\"docsTested\" : 20000,\n",
    "\t\t\"children\" : [ ]\n",
    "\t}\n",
    "}\n",
    "```\n",
    "\n",
    "\n",
    "What this collection needs is an index. You can create an index for the num key within the documents using the `createIndex()` method. Try entering the following index creation code:\n",
    "\n",
    "```mongo\n",
    "> db.numbers.createIndex({num: 1})\n",
    "{\n",
    "\t\"createdCollectionAutomatically\" : false,\n",
    "\t\"numIndexesBefore\" : 1,\n",
    "\t\"numIndexesAfter\" : 2,\n",
    "\t\"ok\" : 1\n",
    "}\n",
    "> db.numbers.getIndexes()\n",
    "[\n",
    "\t{\n",
    "\t\t\"v\" : 1,\n",
    "\t\t\"key\" : {\n",
    "\t\t\t\"_id\" : 1\n",
    "\t\t},\n",
    "\t\t\"name\" : \"_id_\",\n",
    "\t\t\"ns\" : \"users.numbers\"\n",
    "\t},\n",
    "\t{\n",
    "\t\t\"v\" : 1,\n",
    "\t\t\"key\" : {\n",
    "\t\t\t\"num\" : 1\n",
    "\t\t},\n",
    "\t\t\"name\" : \"num_1\",\n",
    "\t\t\"ns\" : \"users.numbers\"\n",
    "\t}\n",
    "]\n",
    "```\n",
    "\n",
    "The collection now has two indexes. The first is the standard `_id` index that’s automatically built for every collection; the second is the index you created on `num`. The indexes for those fields are called `_id_` and `num_1`, respectively. If you don’t provide a name, MongoDB sets hopefully meaningful names automatically.\n",
    "If you run your query with the `explain()` method, you’ll now see the dramatic difference in query response time, as shown in the following listing.\n",
    "\n",
    "```mongo\n",
    "> db.numbers.find({num: {\"$gt\": 19995 }}).explain(\"executionStats\")\n",
    "{\n",
    "\t\"cursor\" : \"BtreeCursor num_1\",\n",
    "\t\"isMultiKey\" : false,\n",
    "\t\"n\" : 4,\n",
    "\t\"nscannedObjects\" : 4,\n",
    "\t\"nscanned\" : 4,\n",
    "\t\"nscannedObjectsAllPlans\" : 4,\n",
    "\t\"nscannedAllPlans\" : 4,\n",
    "\t\"scanAndOrder\" : false,\n",
    "\t\"indexOnly\" : false,\n",
    "\t\"nYields\" : 0,\n",
    "\t\"nChunkSkips\" : 0,\n",
    "\t\"millis\" : 0,\n",
    "\t\"indexBounds\" : {\n",
    "\t\t\"num\" : [\n",
    "\t\t\t[\n",
    "\t\t\t\t19995,\n",
    "\t\t\t\tInfinity\n",
    "\t\t\t]\n",
    "\t\t]\n",
    "\t},\n",
    "\t\"allPlans\" : [\n",
    "\t\t{\n",
    "\t\t\t\"cursor\" : \"BtreeCursor num_1\",\n",
    "\t\t\t\"isMultiKey\" : false,\n",
    "\t\t\t\"n\" : 4,\n",
    "\t\t\t\"nscannedObjects\" : 4,\n",
    "\t\t\t\"nscanned\" : 4,\n",
    "\t\t\t\"scanAndOrder\" : false,\n",
    "\t\t\t\"indexOnly\" : false,\n",
    "\t\t\t\"nChunkSkips\" : 0,\n",
    "\t\t\t\"indexBounds\" : {\n",
    "\t\t\t\t\"num\" : [\n",
    "\t\t\t\t\t[\n",
    "\t\t\t\t\t\t19995,\n",
    "\t\t\t\t\t\tInfinity\n",
    "\t\t\t\t\t]\n",
    "\t\t\t\t]\n",
    "\t\t\t}\n",
    "\t\t}\n",
    "\t],\n",
    "\t\"server\" : \"ubuntu-xenial:27017\",\n",
    "\t\"filterSet\" : false,\n",
    "\t\"stats\" : {\n",
    "\t\t\"type\" : \"FETCH\",\n",
    "\t\t\"works\" : 5,\n",
    "\t\t\"yields\" : 0,\n",
    "\t\t\"unyields\" : 0,\n",
    "\t\t\"invalidates\" : 0,\n",
    "\t\t\"advanced\" : 4,\n",
    "\t\t\"needTime\" : 0,\n",
    "\t\t\"needFetch\" : 0,\n",
    "\t\t\"isEOF\" : 1,\n",
    "\t\t\"alreadyHasObj\" : 0,\n",
    "\t\t\"forcedFetches\" : 0,\n",
    "\t\t\"matchTested\" : 0,\n",
    "\t\t\"children\" : [\n",
    "\t\t\t{\n",
    "\t\t\t\t\"type\" : \"IXSCAN\",\n",
    "\t\t\t\t\"works\" : 4,\n",
    "\t\t\t\t\"yields\" : 0,\n",
    "\t\t\t\t\"unyields\" : 0,\n",
    "\t\t\t\t\"invalidates\" : 0,\n",
    "\t\t\t\t\"advanced\" : 4,\n",
    "\t\t\t\t\"needTime\" : 0,\n",
    "\t\t\t\t\"needFetch\" : 0,\n",
    "\t\t\t\t\"isEOF\" : 1,\n",
    "\t\t\t\t\"keyPattern\" : \"{ num: 1.0 }\",\n",
    "\t\t\t\t\"isMultiKey\" : 0,\n",
    "\t\t\t\t\"boundsVerbose\" : \"field #0['num']: (19995.0, inf.0]\",\n",
    "\t\t\t\t\"yieldMovedCursor\" : 0,\n",
    "\t\t\t\t\"dupsTested\" : 0,\n",
    "\t\t\t\t\"dupsDropped\" : 0,\n",
    "\t\t\t\t\"seenInvalidated\" : 0,\n",
    "\t\t\t\t\"matchTested\" : 0,\n",
    "\t\t\t\t\"keysExamined\" : 4,\n",
    "\t\t\t\t\"children\" : [ ]\n",
    "\t\t\t}\n",
    "\t\t]\n",
    "\t}\n",
    "}\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Connect to MongoDB from a Java Maven Project\n",
    "\n",
    "https://mongodb.github.io/mongo-java-driver/3.0/driver/getting-started/installation-guide/\n",
    "\n",
    "\n",
    "```xml\n",
    "<dependency>\n",
    "    <groupId>org.mongodb</groupId>\n",
    "    <artifactId>mongodb-driver</artifactId>\n",
    "    <version>3.0.4</version>\n",
    "</dependency>\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Based on https://mongodb.github.io/mongo-java-driver/3.0/driver/getting-started/quick-tour/\n",
    "\n",
    "```java\n",
    "package dk.cphbusiness.db.meassurements;\n",
    "\n",
    "import com.mongodb.MongoClient;\n",
    "import com.mongodb.MongoClientURI;\n",
    "import com.mongodb.client.MongoCollection;\n",
    "import com.mongodb.client.MongoDatabase;\n",
    "import org.bson.Document;\n",
    "\n",
    "/**\n",
    " *\n",
    " * @author Helge\n",
    " */\n",
    "public class MongoTest {\n",
    "      \n",
    "    public static void main(String[] args) {\n",
    "        MongoClientURI connStr = new MongoClientURI(\"mongodb://localhost:27017\");\n",
    "        MongoClient mongoClient = new MongoClient(connStr);\n",
    "\n",
    "        MongoDatabase db = mongoClient.getDatabase(\"test-database\");\n",
    "        MongoCollection<Document> collection = db.getCollection(\"tweets\");\n",
    "        \n",
    "        Document myDoc = collection.find().first();\n",
    "        System.out.println(myDoc.toJson());\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Data\n",
    "\n",
    "You can either write a program which inserts documents into a database or you use MongoDB's CLI import tool.\n",
    "\n",
    "```bash\n",
    "mongoimport --drop --db social_net --collection tweets --type csv --headerline --file testdata.manual.2009.06.14.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "This lecture is almost entirely based on chapter one of *\"MongoDB in Action, Second Edition\"* by Kyle Banker, Peter Bakkum, Shaun Verch, Doug Garrett. Additionally, it incorporates parts of \"Appendix A. NOSQL Overview\" from *\"Graph Databases\"* by Ian Robinson, Jim Webber, Emil Eifrem."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
